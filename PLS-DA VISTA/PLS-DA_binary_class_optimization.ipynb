{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838f6fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"mCH_on_off_calc_params.xlsx\"\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Separate features (X) and experimental values (Y)\n",
    "X = data.iloc[:, 5:]  # Features: all columns after the first five\n",
    "Y = data.iloc[:, :5]  # Targets: first five columns\n",
    "\n",
    "target_columns = [\"OFF AVG\", \"ON AVG Truncated\", \"ON AVG Full\", \"ON OFF Truncated\", \"ON OFF Full\"]\n",
    "threshold_high_values = np.arange(0.50, 0.81, 0.05)\n",
    "threshold_low_value = 0.35\n",
    "\n",
    "# Dictionary to collect all data to export to Excel\n",
    "excel_data = {}\n",
    "summary_data = []\n",
    "\n",
    "for i, target in enumerate(target_columns):\n",
    "    for threshold_high_value in threshold_high_values:\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "        threshold_high = Y[target].quantile(threshold_high_value)\n",
    "        threshold_low = Y[target].quantile(threshold_low_value)\n",
    "\n",
    "        if threshold_low >= threshold_high:\n",
    "            continue\n",
    "\n",
    "        Y_classes = pd.cut(Y[target], bins=[-float(\"inf\"), threshold_high, float(\"inf\")], labels=[\"Low\", \"High\"])\n",
    "        label_encoder = LabelEncoder()\n",
    "        Y_encoded = label_encoder.fit_transform(Y_classes)\n",
    "\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "        estimator = LogisticRegression()\n",
    "        selector = RFE(estimator, n_features_to_select=20)\n",
    "        X_train_rfe = selector.fit_transform(X_train, Y_train)\n",
    "        X_test_rfe = selector.transform(X_test)\n",
    "\n",
    "        selected_feature_indices = selector.support_\n",
    "        selected_feature_names = X.columns[selected_feature_indices].tolist()\n",
    "\n",
    "        n_components_range = range(1, min(21, X_train_rfe.shape[1] + 1))\n",
    "        scores = []\n",
    "        for n in n_components_range:\n",
    "            pls = PLSRegression(n_components=n)\n",
    "            X_latent = pls.fit_transform(X_train_rfe, Y_train)[0]\n",
    "            classifier = LogisticRegression()\n",
    "            score = cross_val_score(classifier, X_latent, Y_train, cv=5, scoring='accuracy').mean()\n",
    "            scores.append(score)\n",
    "        best_n_components = n_components_range[np.argmax(scores)]\n",
    "        best_cv_accuracy = max(scores)\n",
    "        cv_error = 1 - best_cv_accuracy\n",
    "\n",
    "        pls = PLSRegression(n_components=best_n_components)\n",
    "        X_train_latent = pls.fit_transform(X_train_rfe, Y_train)[0]\n",
    "        X_test_latent = pls.transform(X_test_rfe)\n",
    "\n",
    "        classifier = LogisticRegression()\n",
    "        classifier.fit(X_train_latent, Y_train)\n",
    "        Y_pred = classifier.predict(X_test_latent)\n",
    "        Y_prob = classifier.predict_proba(X_test_latent)[:, 1]\n",
    "\n",
    "        try:\n",
    "            fpr, tpr, _ = roc_curve(Y_test, Y_prob)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "        except ValueError:\n",
    "            roc_auc = np.nan\n",
    "\n",
    "        precision = precision_score(Y_test, Y_pred, zero_division=0)\n",
    "        recall = recall_score(Y_test, Y_pred, zero_division=0)\n",
    "        f1 = f1_score(Y_test, Y_pred, zero_division=0)\n",
    "\n",
    "        # Save summary stats\n",
    "        summary_data.append({\n",
    "            \"Target\": target,\n",
    "            \"Threshold High\": threshold_high_value,\n",
    "            \"AUROC\": roc_auc,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"F1\": f1,\n",
    "            \"CV Error\": cv_error\n",
    "        })\n",
    "\n",
    "# Save Excel\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df.to_excel(\"threshold_high_sweep_summary.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
